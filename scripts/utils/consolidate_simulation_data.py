#!/usr/bin/env python3
"""
æ¨¡æ‹Ÿæ•°æ®æ•´åˆè„šæœ¬
å°†åˆ†æ•£çš„æŸ“è‰²ä½“æ•°æ®æ•´åˆåˆ°å•ä¸ªæ–‡ä»¶ä¸­ï¼Œå¹¶ç”Ÿæˆæ¸…ç†åçš„æ•°æ®é›†
"""

import os
import json
import gzip
from pathlib import Path
from collections import defaultdict

class DataConsolidator:
    def __init__(self, simulation_dir):
        self.simulation_dir = Path(simulation_dir)
        self.output_dir = Path("consolidated_simulation_data")
        self.chromosome_dirs = []
        self.variants = []
        self.truth_data = []
        
    def discover_chromosome_directories(self):
        """å‘ç°æ‰€æœ‰æŸ“è‰²ä½“ç›®å½•"""
        print("ğŸ” å‘ç°æŸ“è‰²ä½“ç›®å½•...")
        
        chr_dirs = [d for d in self.simulation_dir.iterdir() 
                   if d.is_dir() and d.name.startswith('chr_')]
        
        # æŒ‰æŸ“è‰²ä½“åç§°æ’åº
        chr_dirs.sort(key=lambda x: x.name)
        
        self.chromosome_dirs = chr_dirs
        print(f"âœ… å‘ç° {len(chr_dirs)} ä¸ªæŸ“è‰²ä½“ç›®å½•")
        
        # æ˜¾ç¤ºå‰10ä¸ªå’Œå10ä¸ª
        if len(chr_dirs) > 20:
            print("å‰10ä¸ªæŸ“è‰²ä½“:")
            for i, d in enumerate(chr_dirs[:10]):
                chr_name = d.name.replace('chr_', '')
                print(f"  {i+1:2d}. {chr_name}")
            print("...")
            print("å10ä¸ªæŸ“è‰²ä½“:")
            for i, d in enumerate(chr_dirs[-10:], len(chr_dirs)-9):
                chr_name = d.name.replace('chr_', '')
                print(f"  {i:2d}. {chr_name}")
        else:
            for i, d in enumerate(chr_dirs):
                chr_name = d.name.replace('chr_', '')
                print(f"  {i+1:2d}. {chr_name}")
        
        return chr_dirs
    
    def filter_main_chromosomes(self, max_chromosomes=30):
        """ç­›é€‰ä¸»è¦æŸ“è‰²ä½“ï¼ˆé€šå¸¸æ˜¯NC_å¼€å¤´çš„ï¼‰"""
        print(f"\nğŸ¯ ç­›é€‰å‰ {max_chromosomes} æ¡ä¸»è¦æŸ“è‰²ä½“...")
        
        # åˆ†ç±»æŸ“è‰²ä½“
        main_chrs = []  # NC_å¼€å¤´çš„ä¸»è¦æŸ“è‰²ä½“
        other_chrs = []  # å…¶ä»–æŸ“è‰²ä½“
        
        for chr_dir in self.chromosome_dirs:
            chr_name = chr_dir.name.replace('chr_', '')
            if chr_name.startswith('NC_'):
                main_chrs.append(chr_dir)
            else:
                other_chrs.append(chr_dir)
        
        # æŒ‰åç§°æ’åºä¸»è¦æŸ“è‰²ä½“
        main_chrs.sort(key=lambda x: x.name)
        
        # é€‰æ‹©å‰Næ¡ä¸»è¦æŸ“è‰²ä½“
        selected_chrs = main_chrs[:max_chromosomes]
        
        print(f"ğŸ“Š æŸ“è‰²ä½“åˆ†ç±»:")
        print(f"  - ä¸»è¦æŸ“è‰²ä½“ (NC_): {len(main_chrs)}")
        print(f"  - å…¶ä»–æŸ“è‰²ä½“: {len(other_chrs)}")
        print(f"  - é€‰æ‹©ç”¨äºæ•´åˆ: {len(selected_chrs)}")
        
        print(f"\nâœ… é€‰æ‹©çš„æŸ“è‰²ä½“:")
        for i, chr_dir in enumerate(selected_chrs):
            chr_name = chr_dir.name.replace('chr_', '')
            print(f"  {i+1:2d}. {chr_name}")
        
        self.chromosome_dirs = selected_chrs
        return selected_chrs
    
    def consolidate_vcf_files(self):
        """æ•´åˆæ‰€æœ‰VCFæ–‡ä»¶"""
        print(f"\nğŸ“„ æ•´åˆVCFæ–‡ä»¶...")
        
        self.output_dir.mkdir(exist_ok=True)
        consolidated_vcf = self.output_dir / "consolidated_variants.vcf"
        
        total_variants = 0
        chr_variant_counts = {}
        
        with open(consolidated_vcf, 'w') as outfile:
            # å†™å…¥VCFå¤´éƒ¨
            outfile.write("##fileformat=VCFv4.2\n")
            outfile.write("##source=ConsolidatedSimulation\n")
            outfile.write("##reference=ARS-UCD1.2\n")
            outfile.write("##INFO=<ID=DP,Number=1,Type=Integer,Description=\"Total Depth\">\n")
            outfile.write("##INFO=<ID=AF,Number=1,Type=Float,Description=\"Allele Frequency\">\n")
            outfile.write("##FORMAT=<ID=GT,Number=1,Type=String,Description=\"Genotype\">\n")
            outfile.write("##FORMAT=<ID=DP,Number=1,Type=Integer,Description=\"Read Depth\">\n")
            outfile.write("#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO\tFORMAT\tSample1\n")
            
            # åˆå¹¶æ¯ä¸ªæŸ“è‰²ä½“çš„VCFæ•°æ®
            for chr_dir in self.chromosome_dirs:
                chr_name = chr_dir.name.replace('chr_', '')
                vcf_file = chr_dir / f"{chr_name}_variants.vcf"
                
                if vcf_file.exists():
                    chr_variants = 0
                    with open(vcf_file, 'r') as infile:
                        for line in infile:
                            if not line.startswith('#'):
                                outfile.write(line)
                                chr_variants += 1
                                total_variants += 1
                    
                    chr_variant_counts[chr_name] = chr_variants
                    print(f"  âœ… {chr_name}: {chr_variants:,} å˜å¼‚")
                else:
                    print(f"  âŒ {chr_name}: VCFæ–‡ä»¶ä¸å­˜åœ¨")
        
        print(f"\nğŸ“Š VCFæ•´åˆå®Œæˆ:")
        print(f"  - æ€»å˜å¼‚æ•°: {total_variants:,}")
        print(f"  - è¾“å‡ºæ–‡ä»¶: {consolidated_vcf}")
        
        return consolidated_vcf, chr_variant_counts
    
    def consolidate_truth_sets(self):
        """æ•´åˆæ‰€æœ‰çœŸå€¼é›†åˆ"""
        print(f"\nğŸ¯ æ•´åˆçœŸå€¼é›†åˆ...")
        
        consolidated_truth = self.output_dir / "consolidated_truth_set.json"
        all_variants = []
        chr_stats = {}
        
        for chr_dir in self.chromosome_dirs:
            chr_name = chr_dir.name.replace('chr_', '')
            truth_file = chr_dir / f"{chr_name}_truth_set.json"
            
            if truth_file.exists():
                with open(truth_file, 'r') as f:
                    data = json.load(f)
                    
                    # æå–æŸ“è‰²ä½“ç»Ÿè®¡ä¿¡æ¯
                    if 'metadata' in data:
                        chr_stats[chr_name] = {
                            'length': data['metadata'].get('chromosome_length', 0),
                            'gc_content': data['metadata'].get('gc_content', 0),
                            'variant_count': len(data.get('variants', []))
                        }
                    
                    # æ·»åŠ å˜å¼‚æ•°æ®
                    variants = data.get('variants', [])
                    all_variants.extend(variants)
                    
                    print(f"  âœ… {chr_name}: {len(variants):,} å˜å¼‚")
            else:
                print(f"  âŒ {chr_name}: çœŸå€¼æ–‡ä»¶ä¸å­˜åœ¨")
        
        # æŒ‰æŸ“è‰²ä½“å’Œä½ç½®æ’åº
        all_variants.sort(key=lambda x: (x.get('chromosome', ''), x.get('position', 0)))
        
        # ç”Ÿæˆæ•´åˆçš„çœŸå€¼é›†åˆ
        consolidated_data = {
            'metadata': {
                'description': 'æ•´åˆçš„å¥¶ç‰›åŸºå› ç»„å˜å¼‚çœŸå€¼é›†åˆ',
                'reference': 'ARS-UCD1.2',
                'total_chromosomes': len(self.chromosome_dirs),
                'total_variants': len(all_variants),
                'consolidation_time': __import__('time').strftime('%Y-%m-%d %H:%M:%S'),
                'chromosome_statistics': chr_stats
            },
            'variants': all_variants
        }
        
        with open(consolidated_truth, 'w') as f:
            json.dump(consolidated_data, f, indent=2)
        
        print(f"\nğŸ“Š çœŸå€¼é›†åˆæ•´åˆå®Œæˆ:")
        print(f"  - æ€»å˜å¼‚æ•°: {len(all_variants):,}")
        print(f"  - è¾“å‡ºæ–‡ä»¶: {consolidated_truth}")
        
        return consolidated_truth
    
    def generate_summary_report(self, vcf_file, truth_file, chr_variant_counts):
        """ç”Ÿæˆæ•´åˆæŠ¥å‘Š"""
        print(f"\nğŸ“‹ ç”Ÿæˆæ•´åˆæŠ¥å‘Š...")
        
        report_file = self.output_dir / "consolidation_report.json"
        
        # ç»Ÿè®¡å˜å¼‚ç±»å‹
        variant_types = defaultdict(int)
        total_variants = sum(chr_variant_counts.values())
        
        # ç®€å•ä¼°ç®—ï¼ˆåŸºäºæ¯”ä¾‹ï¼‰
        variant_types['SNP'] = int(total_variants * 0.83)  # çº¦83% SNP
        variant_types['INS'] = int(total_variants * 0.085)  # çº¦8.5% æ’å…¥
        variant_types['DEL'] = total_variants - variant_types['SNP'] - variant_types['INS']  # å…¶ä½™ä¸ºåˆ é™¤
        
        # è®¡ç®—æ€»åŸºå› ç»„å¤§å°ï¼ˆä¼°ç®—ï¼‰
        total_genome_size = sum(chr_variant_counts.values()) / 0.0012 * 1000  # åŸºäºå¯†åº¦åæ¨
        
        report = {
            'consolidation_summary': {
                'total_chromosomes': len(self.chromosome_dirs),
                'total_variants': total_variants,
                'estimated_genome_size': int(total_genome_size),
                'variant_density': total_variants / total_genome_size if total_genome_size > 0 else 0,
                'consolidation_time': __import__('time').strftime('%Y-%m-%d %H:%M:%S')
            },
            'variant_statistics': {
                'total_variants': total_variants,
                'variant_types': dict(variant_types),
                'variants_by_chromosome': chr_variant_counts
            },
            'output_files': {
                'consolidated_vcf': str(vcf_file),
                'consolidated_truth_set': str(truth_file),
                'consolidation_report': str(report_file)
            },
            'chromosome_list': [chr_dir.name.replace('chr_', '') for chr_dir in self.chromosome_dirs]
        }
        
        with open(report_file, 'w') as f:
            json.dump(report, f, indent=2)
        
        print(f"âœ… æŠ¥å‘Šç”Ÿæˆå®Œæˆ: {report_file}")
        return report
    
    def cleanup_original_data(self, keep_original=True):
        """æ¸…ç†åŸå§‹åˆ†æ•£æ•°æ®ï¼ˆå¯é€‰ï¼‰"""
        if not keep_original:
            print(f"\nğŸ§¹ æ¸…ç†åŸå§‹åˆ†æ•£æ•°æ®...")
            for chr_dir in self.chromosome_dirs:
                if chr_dir.exists():
                    import shutil
                    shutil.rmtree(chr_dir)
                    print(f"  ğŸ—‘ï¸  åˆ é™¤: {chr_dir.name}")
            print("âœ… åŸå§‹æ•°æ®æ¸…ç†å®Œæˆ")
        else:
            print(f"\nğŸ’¾ ä¿ç•™åŸå§‹æ•°æ®ï¼ˆå¦‚éœ€æ¸…ç†ï¼Œè¯·è®¾ç½® keep_original=Falseï¼‰")

def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='æ•´åˆåˆ†æ•£çš„æ¨¡æ‹Ÿæ•°æ®')
    parser.add_argument('--simulation-dir', default='./parallel_genome_simulation',
                       help='æ¨¡æ‹Ÿæ•°æ®ç›®å½•')
    parser.add_argument('--max-chromosomes', type=int, default=30,
                       help='æœ€å¤§æŸ“è‰²ä½“æ•°é‡')
    parser.add_argument('--cleanup', action='store_true',
                       help='æ¸…ç†åŸå§‹åˆ†æ•£æ•°æ®')
    
    args = parser.parse_args()
    
    print("ğŸ”„ æ•°æ®æ•´åˆè„šæœ¬")
    print("=" * 50)
    
    # åˆå§‹åŒ–æ•´åˆå™¨
    consolidator = DataConsolidator(args.simulation_dir)
    
    # å‘ç°æŸ“è‰²ä½“ç›®å½•
    consolidator.discover_chromosome_directories()
    
    # ç­›é€‰ä¸»è¦æŸ“è‰²ä½“
    consolidator.filter_main_chromosomes(args.max_chromosomes)
    
    # æ•´åˆVCFæ–‡ä»¶
    vcf_file, chr_counts = consolidator.consolidate_vcf_files()
    
    # æ•´åˆçœŸå€¼é›†åˆ
    truth_file = consolidator.consolidate_truth_sets()
    
    # ç”ŸæˆæŠ¥å‘Š
    report = consolidator.generate_summary_report(vcf_file, truth_file, chr_counts)
    
    # æ¸…ç†åŸå§‹æ•°æ®ï¼ˆå¯é€‰ï¼‰
    consolidator.cleanup_original_data(keep_original=not args.cleanup)
    
    print("\n" + "=" * 50)
    print("ğŸ‰ æ•°æ®æ•´åˆå®Œæˆï¼")
    print("=" * 50)
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {consolidator.output_dir}")
    print(f"ğŸ“„ ä¸»è¦æ–‡ä»¶:")
    print(f"  - VCFæ–‡ä»¶: consolidated_variants.vcf")
    print(f"  - çœŸå€¼é›†åˆ: consolidated_truth_set.json")
    print(f"  - æ•´åˆæŠ¥å‘Š: consolidation_report.json")
    print(f"\nğŸ“Š æ•°æ®ç»Ÿè®¡:")
    print(f"  - æŸ“è‰²ä½“æ•°: {report['consolidation_summary']['total_chromosomes']}")
    print(f"  - æ€»å˜å¼‚æ•°: {report['consolidation_summary']['total_variants']:,}")
    print(f"  - åŸºå› ç»„å¤§å°: {report['consolidation_summary']['estimated_genome_size']:,} bp")

if __name__ == "__main__":
    main()
