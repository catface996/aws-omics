# AWS Omics 奶牛基因组分析 - 快速开始指南

## 概述

本指南将帮助你在30分钟内部署并运行一个完整的奶牛基因组分析流水线，使用AWS Omics服务实现从原始测序数据到生物学解释的端到端分析。

## 前提条件

### 1. AWS账户和权限
- 拥有AWS账户并配置了管理员权限
- 安装并配置了AWS CLI v2
- 确保在支持AWS Omics的区域（如us-east-1, us-west-2, eu-west-1）

### 2. 本地环境
```bash
# 检查AWS CLI版本
aws --version

# 验证AWS凭证
aws sts get-caller-identity

# 检查区域设置
aws configure get region
```

### 3. 服务限额
确保以下AWS服务限额足够：
- EC2 vCPU限额: 至少100个vCPU
- S3存储: 至少10TB
- Omics工作流: 至少10个并发运行

## 快速部署（5分钟）

### 步骤1: 下载部署脚本
```bash
# 克隆或下载项目文件
git clone <repository-url>
cd cattle-genomics-aws-omics

# 或者直接下载脚本
curl -O https://raw.githubusercontent.com/your-repo/deploy_cattle_genomics.sh
chmod +x deploy_cattle_genomics.sh
```

### 步骤2: 运行部署脚本
```bash
./deploy_cattle_genomics.sh
```

部署脚本将自动完成：
- ✅ 创建IAM角色和权限
- ✅ 创建S3存储桶
- ✅ 上传工作流定义
- ✅ 创建AWS Omics工作流
- ✅ 创建参考基因组存储
- ✅ 生成示例数据和运行脚本

### 步骤3: 验证部署
```bash
# 检查创建的资源
cat .env

# 验证S3存储桶
aws s3 ls | grep cattle-genomics

# 验证Omics工作流
aws omics list-workflows --query 'items[?name==`cattle-genomics-pipeline`]'
```

## 准备数据（10分钟）

### 步骤1: 下载奶牛参考基因组
```bash
# 创建临时目录
mkdir -p temp_data && cd temp_data

# 下载奶牛参考基因组 (ARS-UCD1.2)
wget -c http://ftp.ensembl.org/pub/release-107/fasta/bos_taurus/dna/Bos_taurus.ARS-UCD1.2.dna.toplevel.fa.gz

# 解压
gunzip Bos_taurus.ARS-UCD1.2.dna.toplevel.fa.gz

# 上传到S3
BUCKET_NAME=$(cat ../.env | grep BUCKET_NAME | cut -d'=' -f2)
aws s3 cp Bos_taurus.ARS-UCD1.2.dna.toplevel.fa s3://$BUCKET_NAME/reference/

# 创建索引文件
samtools faidx Bos_taurus.ARS-UCD1.2.dna.toplevel.fa
aws s3 cp Bos_taurus.ARS-UCD1.2.dna.toplevel.fa.fai s3://$BUCKET_NAME/reference/

cd ..
```

### 步骤2: 准备测试数据
```bash
# 选项A: 使用模拟数据（推荐用于测试）
# 生成小规模测试数据
python3 << 'EOF'
import random
import gzip

def generate_fastq(filename, num_reads=10000, read_length=150):
    bases = ['A', 'T', 'G', 'C']
    with gzip.open(filename, 'wt') as f:
        for i in range(num_reads):
            # 序列头
            f.write(f"@read_{i+1}\n")
            # 随机序列
            seq = ''.join(random.choices(bases, k=read_length))
            f.write(f"{seq}\n")
            # 质量分隔符
            f.write("+\n")
            # 质量值
            qual = ''.join(['I'] * read_length)  # 高质量值
            f.write(f"{qual}\n")

# 生成测试数据
for sample in ['sample001', 'sample002', 'sample003']:
    generate_fastq(f'{sample}_R1.fastq.gz')
    generate_fastq(f'{sample}_R2.fastq.gz')
    print(f"Generated test data for {sample}")
EOF

# 上传测试数据
for sample in sample001 sample002 sample003; do
    aws s3 cp ${sample}_R1.fastq.gz s3://$BUCKET_NAME/raw-data/$sample/
    aws s3 cp ${sample}_R2.fastq.gz s3://$BUCKET_NAME/raw-data/$sample/
done

# 选项B: 使用真实数据
# 如果你有真实的FASTQ文件，直接上传：
# aws s3 cp your_sample_R1.fastq.gz s3://$BUCKET_NAME/raw-data/your_sample/
# aws s3 cp your_sample_R2.fastq.gz s3://$BUCKET_NAME/raw-data/your_sample/
```

## 运行分析（15分钟）

### 步骤1: 启动分析
```bash
# 使用默认参数运行分析
./run_analysis.sh

# 记录返回的运行ID
RUN_ID="your-run-id-here"
```

### 步骤2: 监控运行状态
```bash
# 方法1: 使用监控脚本
./monitor_runs.sh

# 方法2: 直接使用AWS CLI
aws omics get-run --id $RUN_ID --query '{Status:status,CreationTime:creationTime,StartTime:startTime}'

# 方法3: 查看任务详情
aws omics list-run-tasks --id $RUN_ID --query 'items[].[name,status,creationTime]' --output table
```

### 步骤3: 查看日志（如果需要调试）
```bash
# 列出日志组
aws logs describe-log-groups --log-group-name-prefix /aws/omics

# 查看特定日志流
aws logs describe-log-streams --log-group-name /aws/omics/WorkflowLog --order-by LastEventTime --descending

# 获取日志事件
aws logs get-log-events --log-group-name /aws/omics/WorkflowLog --log-stream-name your-log-stream-name
```

## 查看结果

### 分析完成后的输出文件
```bash
# 列出结果文件
aws s3 ls s3://$BUCKET_NAME/results/ --recursive

# 下载主要结果文件
mkdir -p results
aws s3 cp s3://$BUCKET_NAME/results/your-run-name/ ./results/ --recursive

# 主要输出文件：
# - filtered_variants.vcf.gz: 过滤后的变异文件
# - *_qc_report.html: 质量控制报告
# - *_dedup.bam: 去重后的比对文件
# - *_metrics.txt: 比对统计信息
```

### 结果解读
1. **质量控制报告**: 查看测序质量和预处理效果
2. **变异文件**: 包含检测到的SNP和INDEL
3. **比对统计**: 评估比对质量和覆盖度
4. **运行日志**: 了解每个步骤的执行情况

## 成本估算

### 测试运行（3个样本，模拟数据）
- **计算成本**: ~$5-10
- **存储成本**: ~$1-2/月
- **总成本**: ~$6-12

### 生产运行（100个样本，30X覆盖度）
- **计算成本**: ~$500-1000
- **存储成本**: ~$50-100/月
- **数据传输**: ~$20-50
- **总成本**: ~$570-1150

## 故障排除

### 常见问题

**1. 权限错误**
```bash
# 检查IAM角色
aws iam get-role --role-name OmicsWorkflowExecutionRole

# 检查S3权限
aws s3 ls s3://your-bucket-name
```

**2. 工作流失败**
```bash
# 查看运行详情
aws omics get-run --id $RUN_ID

# 查看失败任务
aws omics list-run-tasks --id $RUN_ID --status FAILED
```

**3. 资源不足**
```bash
# 检查服务限额
aws service-quotas get-service-quota --service-code ec2 --quota-code L-34B43A08

# 请求增加限额（如需要）
aws service-quotas request-service-quota-increase \
  --service-code ec2 \
  --quota-code L-34B43A08 \
  --desired-value 200
```

### 获取帮助
- AWS Omics文档: https://docs.aws.amazon.com/omics/
- AWS支持: 通过AWS控制台提交支持案例
- 社区论坛: AWS re:Post

## 清理资源

### 完成测试后清理（避免持续费用）
```bash
# 删除S3存储桶内容
aws s3 rm s3://$BUCKET_NAME --recursive

# 删除S3存储桶
aws s3 rb s3://$BUCKET_NAME

# 删除IAM角色
aws iam delete-role-policy --role-name OmicsWorkflowExecutionRole --policy-name OmicsWorkflowExecutionPolicy
aws iam delete-role --role-name OmicsWorkflowExecutionRole

# 注意：Omics工作流和参考存储需要通过控制台手动删除
```

## 下一步

### 扩展分析
1. **添加更多样本**: 修改参数文件增加样本数量
2. **自定义工作流**: 编辑WDL文件添加新的分析步骤
3. **集成下游分析**: 添加GWAS、群体遗传学分析等

### 生产部署
1. **设置监控告警**: 配置CloudWatch告警
2. **实施成本控制**: 设置预算和成本告警
3. **数据管理**: 配置自动化数据归档策略
4. **安全加固**: 实施最小权限原则和数据加密

### 学习资源
- [AWS Omics Workshop](https://catalog.workshops.aws/omics-end-to-end)
- [生物信息学最佳实践](https://aws.amazon.com/blogs/hpc/genomics-workflows-part-1-common-workflow-language/)
- [WDL语言教程](https://github.com/openwdl/wdl/blob/main/versions/1.0/SPEC.md)

---

**恭喜！** 你已经成功部署并运行了AWS Omics奶牛基因组分析流水线。这个基础框架可以根据你的具体需求进行扩展和定制。
